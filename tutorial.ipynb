{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e1adb0",
   "metadata": {},
   "source": [
    "# Tutorial file\n",
    "\n",
    "This is a supportive file for whomever would like to run the final experimental results. \n",
    "\n",
    "It includes:\n",
    "    \n",
    "    Reading the features extracted for both annotations by the ResNet model\n",
    "\n",
    "    Performing classification with such features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc1ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread \n",
    "import PIL\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import plotly.express as px\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ebdef2",
   "metadata": {},
   "source": [
    "# Retrieving extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d68b1",
   "metadata": {},
   "source": [
    "    Loading resnet training behavior features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b223749b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train\u001b[38;5;241m.\u001b[39mpath:    \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(i) \u001b[38;5;28;01mas\u001b[39;00m file_name:\n\u001b[0;32m---> 15\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         train_features\u001b[38;5;241m.\u001b[39mappend(array)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/lib/npyio.py:1148\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;66;03m# read data in chunks and fill it into an array via resize\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;66;03m# over-allocating and shrinking the array later may be faster but is\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;66;03m# probably not relevant compared to the cost of actually reading and\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;66;03m# converting the data\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m read_data(_loadtxt_chunksize):\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1150\u001b[0m         X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x, dtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/lib/npyio.py:1002\u001b[0m, in \u001b[0;36mloadtxt.<locals>.read_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m    999\u001b[0m items \u001b[38;5;241m=\u001b[39m [conv(val) \u001b[38;5;28;01mfor\u001b[39;00m (conv, val) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(converters, vals)]\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# Then pack it according to the dtype's nesting\u001b[39;00m\n\u001b[0;32m-> 1002\u001b[0m items \u001b[38;5;241m=\u001b[39m \u001b[43mpack_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(items)\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m>\u001b[39m chunk_size:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/core/_internal.py:909\u001b[0m, in \u001b[0;36mrecursive.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 909\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RN = sorted(glob.glob(r'data/all_features/mid-level/RN-beh/*.csv'))\n",
    "sorted_array = natsorted(RN, key=lambda x:(x[29].isdigit(), x))\n",
    "RN_labels = pd.read_csv('data/MotionEmotion/reduced_beh_labelled_dataset.csv')\n",
    "training_df = pd.DataFrame()\n",
    "training_df['path'] = sorted_array\n",
    "training_df['label'] = RN_labels['label']\n",
    "neutral = training_df[training_df['label'] == 5].sample(n=650)\n",
    "neutral_ = training_df[training_df['label']== 5].index\n",
    "training_df.drop(neutral_, inplace=True)\n",
    "train = pd.concat((training_df,neutral))\n",
    "train_features = [ ]\n",
    "train_labels = train.label\n",
    "for i in train.path:    \n",
    "    with open(i) as file_name:\n",
    "        array = np.loadtxt(file_name, delimiter=\",\")\n",
    "        train_features.append(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514cb3d",
   "metadata": {},
   "source": [
    "\n",
    "    plotting class distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(train, x=\"label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fccfa1e",
   "metadata": {},
   "source": [
    "    testing behavior features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513fab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ = pd.read_csv('data/MotionEmotion/test_set_beh.csv')\n",
    "testingg = sorted(glob.glob(r'data/all_features/RN_test_beh/*.csv'))\n",
    "sorted_test = natsorted(testingg, key=lambda x:(x[29].isdigit(), x))\n",
    "testing = pd.DataFrame()\n",
    "testing['path'] = sorted_test\n",
    "testing['label'] = testing_.test_labels \n",
    "test_features = [ ]\n",
    "test_labels_ = testing.label\n",
    "for i_ in testing.path:    \n",
    "    with open(i_) as _file_name_:\n",
    "        array_ = np.loadtxt(_file_name_, delimiter=\",\")\n",
    "        test_features.append(array_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2345b85",
   "metadata": {},
   "source": [
    "    Loading resnet training emotion features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f642b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RN_e = sorted(glob.glob(r'data/all_features/mid-level/RN-emo/*.csv'))\n",
    "RN_e_labels = pd.read_csv('data/MotionEmotion/reduced_emo_labelled_dataset.csv')\n",
    "sorted_e_array = natsorted(RN_e, key=lambda x:(x[29].isdigit(), x))\n",
    "training_df_e = pd.DataFrame()\n",
    "training_df_e['path'] = sorted_e_array\n",
    "training_df_e['label'] = RN_e_labels['label']\n",
    "e_neutral = training_df_e[training_df_e['label'] == 6].sample(n=650)\n",
    "e_neutral_ = training_df_e[training_df_e['label']== 6].index\n",
    "training_df_e.drop(e_neutral_, inplace=True)\n",
    "train_e = pd.concat((training_df_e,e_neutral))\n",
    "train_features_e = [ ]\n",
    "train_labels_e = train_e.label\n",
    "for j in train_e.path:    \n",
    "    with open(j) as file_name_:\n",
    "        array_e = np.loadtxt(file_name_, delimiter=\",\")\n",
    "        train_features_e.append(array_e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9439297b",
   "metadata": {},
   "source": [
    "    plotting class distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(train_b, x=\"label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47230416",
   "metadata": {},
   "source": [
    "     loading restnet testing emotion features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_emo_ = pd.read_csv('data/MotionEmotion/test_set.csv')\n",
    "testing_e = sorted(glob.glob(r'data/all_features/RN_test_features/*.csv'))\n",
    "sorted_test_e = natsorted(testing_e, key=lambda x:(x[29].isdigit(), x))\n",
    "test_labels_e = testing_emo_.test_labels \n",
    "testing_e = pd.DataFrame()\n",
    "testing_e['path'] = sorted_test_e\n",
    "testing_e['label'] = test_labels_e\n",
    "test_features_e = [ ]\n",
    "\n",
    "for j_ in testing_e.path:    \n",
    "    with open(j_) as file_name_e:\n",
    "        array_e = np.loadtxt(file_name_e, delimiter=\",\")\n",
    "        test_features_e.append(array_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e6090e",
   "metadata": {},
   "source": [
    "# Training and testing SVM classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train emotion \n",
    "linear_e = svm.SVC(kernel='linear', decision_function_shape='ovo').fit(train_features_e, train_labels_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f004d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test emotion\n",
    "linear_pred = linear_e.predict(test_features_e)\n",
    "accuracy_lin = linear_e.score(test_features_e, test_labels_e)\n",
    "\n",
    "cm_lin = confusion_matrix(test_labels, test_labels_e)\n",
    "print('Accuracy Linear Kernel:', accuracy_lin)\n",
    "fig, ax = plt.subplots(figsize=(8,8))         # Sample figsize in inches\n",
    "ax = sns.heatmap(cm_lin, annot=True, cmap='Blues',annot_kws={\"size\": 14}, fmt='g',cbar=False)\n",
    "print(classification_report(test_labels_e, linear_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train behaviour\n",
    "linear = svm.SVC(kernel='linear', decision_function_shape='ovo').fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test behaviour\n",
    "linear_pred = linear.predict(test_features)\n",
    "accuracy_lin = linear.score(test_features, test_labels)\n",
    "cm_lin = confusion_matrix(test_labels, linear_pred)\n",
    "print('Accuracy Linear Kernel:', accuracy_lin)\n",
    "fig, ax = plt.subplots(figsize=(8,8))         # Sample figsize in inches\n",
    "ax = sns.heatmap(cm_lin, annot=True, cmap='Blues',annot_kws={\"size\": 14}, fmt='g',cbar=False)\n",
    "print(classification_report(test_labels, linear_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c27df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
